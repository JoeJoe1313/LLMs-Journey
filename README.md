# LLMs-Journey

## What to read?

Books:
- [Foundations of Large Language Models](https://arxiv.org/pdf/2501.09223)

Agents:
- [Agents (Google's whitepaper)](https://www.kaggle.com/whitepaper-agents)

Fine-Tuning:
- [LoRA: Low-Rank Adaptation of Large Language Models](https://arxiv.org/pdf/2106.09685)
- [QLORA: Efficient Finetuning of Quantized LLMs](https://arxiv.org/pdf/2305.14314)

RAG related:
- [Chain-of-Retrieval Augmented Generation](https://arxiv.org/pdf/2501.14342)

Evaluation:
- [A Survey on LLM-as-a-Judge](https://arxiv.org/pdf/2411.15594)
- [ARC Prize 2024: Technical Report](https://arxiv.org/pdf/2412.04604)
- [FrontierMath: A Benchmark for Evaluating Advanced Mathematical Reasoning in AI](https://arxiv.org/pdf/2411.04872)

Models:
- [DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning](https://arxiv.org/pdf/2501.12948)
- [DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models](https://arxiv.org/pdf/2402.03300)
- [Janus-Pro: Unified Multimodal Understanding and Generation with Data and Model Scaling](https://github.com/deepseek-ai/Janus/blob/main/janus_pro_tech_report.pdf)
- [RoFormer: Enhanced Transformer with Rotary Position Embedding](https://arxiv.org/pdf/2104.09864) and [Round and Round We Go! What makes Rotary Positional Encodings useful?](https://arxiv.org/pdf/2410.06205)

## Resources

MLX:
- [mlx-examples](https://github.com/ml-explore/mlx-examples/tree/main)
- [ml-explore](https://github.com/ml-explore)
- [mlx-vlm](https://github.com/Blaizzy/mlx-vlm)

LangChain:
- [Build a Retrieval Augmented Generation (RAG) App: Part 1](https://python.langchain.com/docs/tutorials/rag/)

LangGraph:
- l

LangSmith:
- l

Ollama:
- l

Databases:
- [Chroma](https://www.trychroma.com/home)

HuggingFace:
- [MLX Community](https://huggingface.co/mlx-community)
- [Using MLX at Hugging Face](https://huggingface.co/docs/hub/en/mlx)

Leonie Notebooks:
- [Fine-tuning Gemma 2 JPN for Yomigana with LoRA](https://www.kaggle.com/code/iamleonie/fine-tuning-gemma-2-jpn-for-yomigana-with-lora)
- [Advanced RAG with Gemma, Weaviate, and LlamaIndex](https://www.kaggle.com/code/iamleonie/advanced-rag-with-gemma-weaviate-and-llamaindex)
- [RAG with Gemma on HF ðŸ¤— and Weaviate in DSPy](https://www.kaggle.com/code/iamleonie/rag-with-gemma-on-hf-and-weaviate-in-dspy)

GitHub Repos:
- [rag-cookbooks](https://github.com/athina-ai/rag-cookbooks)
- [Hands-On-Large-Language-Models](https://github.com/HandsOnLLM/Hands-On-Large-Language-Models)
- [Multimodal-RAG-Implementation](https://github.com/CornelliusYW/Multimodal-RAG-Implementation)
- [Data_Science_Learning_Material](https://github.com/CornelliusYW/Data_Science_Learning_Material)
- [RAG-To-Know](https://github.com/CornelliusYW/RAG-To-Know)
