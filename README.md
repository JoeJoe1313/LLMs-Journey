# LLMs-Journey

## What to read?

- [LoRA: Low-Rank Adaptation of Large Language Models](https://arxiv.org/pdf/2106.09685)

- [A Survey on LLM-as-a-Judge](https://arxiv.org/pdf/2411.15594)

- [Foundations of Large Language Models](https://arxiv.org/pdf/2501.09223)

- [Agents (Google's whitepaper)](https://www.kaggle.com/whitepaper-agents)

- [DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning](https://arxiv.org/pdf/2501.12948)

- [DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models](https://arxiv.org/pdf/2402.03300)

- [Janus-Pro: Unified Multimodal Understanding and Generation with Data and Model Scaling](https://github.com/deepseek-ai/Janus/blob/main/janus_pro_tech_report.pdf)

- [FrontierMath: A Benchmark for Evaluating Advanced Mathematical Reasoning in AI](https://arxiv.org/pdf/2411.04872)

- [ARC Prize 2024: Technical Report](https://arxiv.org/pdf/2412.04604)

- [Chain-of-Retrieval Augmented Generation](https://arxiv.org/pdf/2501.14342)

## Frameworks
