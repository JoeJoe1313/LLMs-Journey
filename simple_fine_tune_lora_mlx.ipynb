{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlx_lm import generate, load\n",
    "from datasets import load_dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Optional\n",
    "\n",
    "from transformers import PreTrainedTokenizer\n",
    "\n",
    "\n",
    "class Dataset:\n",
    "    \"\"\"\n",
    "    Light-weight wrapper to hold a dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data: List[Dict[str, str]],\n",
    "        tokenizer: PreTrainedTokenizer,\n",
    "        text_key: str = \"text\",\n",
    "    ):\n",
    "        self._data = [tokenizer.encode(d[text_key]) for d in data]\n",
    "        for d in self._data:\n",
    "            if d[-1] != tokenizer.eos_token_id:\n",
    "                d.append(tokenizer.eos_token_id)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        return self._data[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._data)\n",
    "\n",
    "\n",
    "class ChatDataset:\n",
    "    \"\"\"\n",
    "    A dataset for chat data in the format of {\"messages\": [...]}\n",
    "    https://platform.openai.com/docs/guides/fine-tuning/example-format\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data: List[Dict[str, str]], tokenizer: PreTrainedTokenizer):\n",
    "        self._data = [\n",
    "            tokenizer.apply_chat_template(\n",
    "                d[\"messages\"],\n",
    "                tools=d.get(\"tools\", None),\n",
    "            )\n",
    "            for d in data\n",
    "        ]\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        return self._data[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._data)\n",
    "\n",
    "\n",
    "class CompletionsDataset:\n",
    "    \"\"\"\n",
    "    A dataset for prompt-completion data in the format of {\"prompt\": ..., \"completion\": ...}\n",
    "    or using user-provided keys for prompt and completion values\n",
    "    https://platform.openai.com/docs/guides/fine-tuning/example-format\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data: List[Dict[str, str]],\n",
    "        tokenizer: PreTrainedTokenizer,\n",
    "        prompt_key: str,\n",
    "        completion_key: str,\n",
    "    ):\n",
    "        self._data = [\n",
    "            tokenizer.apply_chat_template(\n",
    "                [\n",
    "                    {\"role\": \"user\", \"content\": d[prompt_key]},\n",
    "                    {\"role\": \"assistant\", \"content\": d[completion_key]},\n",
    "                ],\n",
    "            )\n",
    "            for d in data\n",
    "        ]\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        return self._data[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._data)\n",
    "\n",
    "\n",
    "def create_dataset(\n",
    "    data,\n",
    "    tokenizer: PreTrainedTokenizer,\n",
    "    prompt_feature: Optional[str] = None,\n",
    "    completion_feature: Optional[str] = None,\n",
    "):\n",
    "    prompt_feature = prompt_feature or \"prompt\"\n",
    "    completion_feature = completion_feature or \"completion\"\n",
    "    sample = data[0]\n",
    "    if \"messages\" in sample:\n",
    "        return ChatDataset(data, tokenizer)\n",
    "    elif prompt_feature in sample and completion_feature in sample:\n",
    "        return CompletionsDataset(data, tokenizer, prompt_feature, completion_feature)\n",
    "    elif \"text\" in sample:\n",
    "        return Dataset(data, tokenizer)\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"Unsupported data format, check the supported formats here:\\n\"\n",
    "            \"https://github.com/ml-explore/mlx-examples/blob/main/llms/mlx_lm/LORA.md#data.\"\n",
    "        )\n",
    "\n",
    "\n",
    "def load_hf_dataset(\n",
    "    data_id: str,\n",
    "    tokenizer: PreTrainedTokenizer,\n",
    "    prompt_feature: Optional[str] = None,\n",
    "    completion_feature: Optional[str] = None,\n",
    "):\n",
    "    from datasets import exceptions, load_dataset\n",
    "\n",
    "    try:\n",
    "        dataset = load_dataset(data_id)\n",
    "\n",
    "        names = (\"train\", \"validation\", \"test\")\n",
    "\n",
    "        train, valid, test = [\n",
    "            (\n",
    "                create_dataset(\n",
    "                    dataset[n], tokenizer, prompt_feature, completion_feature\n",
    "                )\n",
    "                if n in dataset.keys()\n",
    "                else []\n",
    "            )\n",
    "            for n in names\n",
    "        ]\n",
    "\n",
    "    except exceptions.DatasetNotFoundError:\n",
    "        raise ValueError(f\"Not found Hugging Face dataset: {data_id} .\")\n",
    "\n",
    "    return train, valid, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5da56fd384fc453dada272eeca47b727",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 7 files:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_path = \"mlx-community/Mistral-7B-Instruct-v0.3-4bit\"\n",
    "# model_path = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "model, tokenizer = load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "Under-fitting and overfitting are two common problems that can occur when training machine learning models.\n",
      "\n",
      "1. Under-fitting: This occurs when a model is too simple to learn the underlying pattern in the data. In other words, the model is not complex enough to capture the relationship between the input and output variables. As a result, the model's performance on both the training and test data is poor. This can happen when the model has too few parameters, or when the model is not trained for long enough.\n",
      "\n",
      "2. Overfitting: This occurs when a model is too complex and starts to fit the noise in the data instead of the underlying pattern. In other words, the model is learning the idiosyncrasies of the training data rather than the general pattern that applies to new, unseen data. As a result, the model performs well on the training data but poorly on the test data. This can happen when the model has too many parameters, or when the model is trained for too long.\n",
      "\n",
      "The goal in machine learning is to find a balance between under-fitting and overfitting, where the model is complex enough to capture the underlying pattern in the data, but not so complex that it starts\n",
      "==========\n",
      "Prompt: 19 tokens, 44.826 tokens-per-sec\n",
      "Generation: 256 tokens, 30.764 tokens-per-sec\n",
      "Peak memory: 12.232 GB\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What is under-fitting and overfitting in machine learning?\"\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "prompt = tokenizer.apply_chat_template(\n",
    "    messages, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "\n",
    "response = generate(model, tokenizer, prompt=prompt, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Under-fitting and overfitting are two common problems that can occur when training machine learning models.\n",
      "\n",
      "1. Under-fitting: This occurs when a model is too simple to learn the underlying pattern in the data. In other words, the model is not complex enough to capture the relationship between the input and output variables. As a result, the model's performance on both the training and test data is poor. This can happen when the model has too few parameters, or when the model is not trained for long enough.\n",
      "\n",
      "2. Overfitting: This occurs when a model is too complex and starts to fit the noise in the data instead of the underlying pattern. In other words, the model is learning the idiosyncrasies of the training data rather than the general pattern that applies to new, unseen data. As a result, the model performs well on the training data but poorly on the test data. This can happen when the model has too many parameters, or when the model is trained for too long.\n",
      "\n",
      "The goal in machine learning is to find a balance between under-fitting and overfitting, where the model is complex enough to capture the underlying pattern in the data, but not so complex that it starts\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, valid_set, test_set = load_hf_dataset(\"win-wang/Machine_Learning_QA_Collection\", tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = load_dataset(\"win-wang/Machine_Learning_QA_Collection\")\n",
    "# ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splits = {'train': 'train.jsonl', 'validation': 'valid.jsonl', 'test': 'test.jsonl'}\n",
    "# df = pd.read_json(\"hf://datasets/win-wang/Machine_Learning_QA_Collection/\" + splits[\"train\"], lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set = pd.DataFrame(ds[\"train\"])\n",
    "# dev_set = pd.DataFrame(ds[\"validation\"])\n",
    "# test_set = pd.DataFrame(ds[\"test\"])\n",
    "# train_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLX requires the data to be placed in a container that allows random access. Here, we convert it into a Python built-in list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess(dataset):\n",
    "#     return dataset[\"text\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set, dev_set, test_set = map(preprocess, (train_set, dev_set, test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import mlx.optimizers as optim\n",
    "from mlx.utils import tree_flatten\n",
    "from mlx_lm import load, generate\n",
    "from mlx_lm.tuner import train, TrainingArgs\n",
    "from mlx_lm.tuner import linear_to_lora_layers\n",
    "from pathlib import Path\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapter_path = Path(\"adapters\")\n",
    "adapter_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the LoRA parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = {\n",
    " \"lora_layers\": 8,\n",
    " \"lora_parameters\": {\n",
    "    \"rank\": 8,\n",
    "    \"scale\": 20.0,\n",
    "    \"dropout\": 0.0,\n",
    "}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(adapter_path / \"adapter_config.json\", \"w\") as fid:\n",
    "    json.dump(lora_config, fid, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the training parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArgs(\n",
    "    adapter_file=adapter_path / \"adapters.safetensors\",\n",
    "    iters=50,\n",
    "    steps_per_eval=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Freeze the base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): QuantizedEmbedding(32768, 4096, group_size=64, bits=4)\n",
       "    (layers.0): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.1): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.2): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.3): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.4): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.5): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.6): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.7): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.8): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.9): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.10): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.11): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.12): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.13): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.14): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.15): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.16): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.17): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.18): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.19): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.20): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.21): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.22): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.23): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.24): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.25): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.26): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.27): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.28): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.29): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.30): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.31): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (norm): RMSNorm(4096, eps=1e-05)\n",
       "  )\n",
       "  (lm_head): QuantizedLinear(input_dims=4096, output_dims=32768, bias=False, group_size=64, bits=4)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.freeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the linear layers to LoRA layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_to_lora_layers(model, lora_config[\"lora_layers\"], lora_config[\"lora_parameters\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the trainable model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters: 3407872\n"
     ]
    }
   ],
   "source": [
    "num_train_params = (\n",
    "    sum(v.size for _, v in tree_flatten(model.trainable_parameters()))\n",
    ")\n",
    "print(f\"Number of trainable parameters: {num_train_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): QuantizedEmbedding(32768, 4096, group_size=64, bits=4)\n",
       "    (layers.0): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.1): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.2): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.3): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.4): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.5): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.6): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.7): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.8): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.9): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.10): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.11): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.12): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.13): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.14): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.15): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.16): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.17): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.18): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.19): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.20): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.21): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.22): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.23): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.24): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.25): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.26): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.27): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.28): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.29): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.30): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.31): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (norm): RMSNorm(4096, eps=1e-05)\n",
       "  )\n",
       "  (lm_head): QuantizedLinear(input_dims=4096, output_dims=32768, bias=False, group_size=64, bits=4)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.Adam(learning_rate=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class to record the data during the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics:\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    def on_train_loss_report(self, info):\n",
    "        self.train_losses.append((info[\"iteration\"], info[\"train_loss\"]))\n",
    "    def on_val_loss_report(self, info):\n",
    "        self.val_losses.append((info[\"iteration\"], info[\"val_loss\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = Metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, valid_set, test_set = load_hf_dataset(\"win-wang/Machine_Learning_QA_Collection\", tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1235"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training..., iters: 50\n",
      "Iter 1: Val loss 2.579, Val took 65.140s\n",
      "Iter 10: Val loss 1.927, Val took 69.441s\n",
      "Iter 10: Train loss 2.034, Learning Rate 1.000e-05, It/sec 1.643, Tokens/sec 1642.396, Trained Tokens 9996, Peak mem 19.220 GB\n",
      "Iter 20: Val loss 1.762, Val took 61.352s\n",
      "Iter 20: Train loss 1.831, Learning Rate 1.000e-05, It/sec 0.412, Tokens/sec 474.226, Trained Tokens 21493, Peak mem 23.328 GB\n",
      "Iter 30: Val loss 1.797, Val took 89.241s\n",
      "Iter 30: Train loss 1.789, Learning Rate 1.000e-05, It/sec 0.627, Tokens/sec 850.329, Trained Tokens 35050, Peak mem 27.941 GB\n",
      "Iter 40: Val loss 1.703, Val took 66.019s\n",
      "Iter 40: Train loss 1.791, Learning Rate 1.000e-05, It/sec 0.434, Tokens/sec 477.655, Trained Tokens 46065, Peak mem 27.941 GB\n",
      "Iter 50: Val loss 1.857, Val took 64.510s\n",
      "Iter 50: Train loss 1.766, Learning Rate 1.000e-05, It/sec 0.784, Tokens/sec 782.464, Trained Tokens 56040, Peak mem 27.941 GB\n",
      "Saved final weights to adapters/adapters.safetensors.\n"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    optimizer=opt,\n",
    "    train_dataset=train_set,\n",
    "    val_dataset=valid_set,\n",
    "    training_callback=metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_its, train_losses = zip(*metrics.train_losses)\n",
    "val_its, val_losses = zip(*metrics.val_losses)\n",
    "plt.plot(train_its, train_losses, '-o')\n",
    "plt.plot(val_its, val_losses, '-o')\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(['Train', \"Valid\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa888887260a4b80963c0625187edc31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 7 files:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_lora, _ = load(model_path, adapter_path=\"adapters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b13a201707d456faa7f4404c41c7d68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 7 files:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_lora, _ = load(model_path, adapter_path=\"adapters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "Under-fitting and overfitting are two common problems in machine learning.\n",
      "\n",
      "Under-fitting occurs when a model is too simple and fails to capture the underlying patterns in the data, resulting in poor performance on the training data and poor generalization to new data. This can happen when the model is too simple, the training data is too small, or the model is not flexible enough to capture the complexity of the data.\n",
      "\n",
      "Overfitting occurs when a model is too complex and fits the training data too closely, resulting in poor performance on new data. This can happen when the model is too complex, the training data is too large, or the model is too flexible. Overfitting can lead to poor generalization, as the model may capture noise and outliers in the training data that are not representative of the underlying patterns in the data.\n",
      "\n",
      "In both cases, the model may not generalize well to new data, leading to poor performance on the test set. To avoid these problems, it is important to find a balance between the complexity of the model and the amount of training data, and to use techniques such as regularization and cross-validation to prevent overfitting.\n",
      "==========\n",
      "Prompt: 19 tokens, 163.983 tokens-per-sec\n",
      "Generation: 246 tokens, 27.621 tokens-per-sec\n",
      "Peak memory: 12.232 GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Under-fitting and overfitting are two common problems in machine learning.\\n\\nUnder-fitting occurs when a model is too simple and fails to capture the underlying patterns in the data, resulting in poor performance on the training data and poor generalization to new data. This can happen when the model is too simple, the training data is too small, or the model is not flexible enough to capture the complexity of the data.\\n\\nOverfitting occurs when a model is too complex and fits the training data too closely, resulting in poor performance on new data. This can happen when the model is too complex, the training data is too large, or the model is too flexible. Overfitting can lead to poor generalization, as the model may capture noise and outliers in the training data that are not representative of the underlying patterns in the data.\\n\\nIn both cases, the model may not generalize well to new data, leading to poor performance on the test set. To avoid these problems, it is important to find a balance between the complexity of the model and the amount of training data, and to use techniques such as regularization and cross-validation to prevent overfitting.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(model_lora, tokenizer, prompt=prompt, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
